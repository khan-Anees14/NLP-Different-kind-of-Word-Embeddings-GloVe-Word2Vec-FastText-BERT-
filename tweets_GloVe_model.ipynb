{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7dee6d",
   "metadata": {},
   "source": [
    "### **Train a deep neural network model in PyTorch for multi-label text classification** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f667590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet = pd.read_csv('mLabel_tweets.csv', usecols=[1,2], names=['tweet', 'labels'],skiprows=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d58b0c",
   "metadata": {},
   "source": [
    "### **Preprocess text before loding to model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c62ecea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NCS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NCS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "lematizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    words = text.split()\n",
    "\n",
    "    clean_words = [ lematizer.lemmatize(w) for w in words if w not in stopwords ]\n",
    "\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "tweet['tweet'] = tweet['tweet'].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f55b3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6944,), (2977,), (6944,), (2977,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tweet['tweet']\n",
    "y = tweet['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f261fdf",
   "metadata": {},
   "source": [
    "### **Multi Label Binarizer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7d9eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test  = mlb.transform(y_test)\n",
    "\n",
    "num_classes = len(mlb.classes_)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5029d",
   "metadata": {},
   "source": [
    "### **Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "075c96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_text(docs):\n",
    "    return [ [w.lower() for w in word_tokenize(text) if w.isalpha()] for text in docs ]\n",
    "\n",
    "X_train_tokens = tokenize_text(X_train)\n",
    "X_test_tokens  = tokenize_text(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883b507",
   "metadata": {},
   "source": [
    "### **Glove Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9860ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "glove_model = api.load('glove-wiki-gigaword-50')\n",
    "EMB_DIM = glove_model.vector_size\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert documents â†’ vector embeddings\n",
    "def document_vector(tokens):\n",
    "    tokens = [w for w in tokens if w in glove_model]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(EMB_DIM)\n",
    "    return np.mean(glove_model[tokens], axis=0)\n",
    "\n",
    "X_train_vec = np.array([document_vector(t) for t in X_train_tokens], dtype=np.float32)\n",
    "X_test_vec  = np.array([document_vector(t) for t in X_test_tokens], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd1d8b",
   "metadata": {},
   "source": [
    "### **Creating DataLoaders to feed into MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5772705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_vec), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset  = TensorDataset(torch.tensor(X_test_vec), torch.tensor(y_test,  dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935eac0",
   "metadata": {},
   "source": [
    "### **Text Classifier MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57a61cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_feature, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, out_feature)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "mlp_model = TextClassifier(EMB_DIM, num_classes).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e2933b",
   "metadata": {},
   "source": [
    "### **Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8947223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Train Loss: 0.45 | Train Accuracy: 0.7807\n",
      "Epoch [2/50] Train Loss: 0.45 | Train Accuracy: 0.7804\n",
      "Epoch [3/50] Train Loss: 0.45 | Train Accuracy: 0.7812\n",
      "Epoch [4/50] Train Loss: 0.45 | Train Accuracy: 0.7816\n",
      "Epoch [5/50] Train Loss: 0.45 | Train Accuracy: 0.7816\n",
      "Epoch [6/50] Train Loss: 0.45 | Train Accuracy: 0.7815\n",
      "Epoch [7/50] Train Loss: 0.45 | Train Accuracy: 0.7804\n",
      "Epoch [8/50] Train Loss: 0.45 | Train Accuracy: 0.7824\n",
      "Epoch [9/50] Train Loss: 0.45 | Train Accuracy: 0.7821\n",
      "Epoch [10/50] Train Loss: 0.45 | Train Accuracy: 0.7821\n",
      "Epoch [11/50] Train Loss: 0.45 | Train Accuracy: 0.7823\n",
      "Epoch [12/50] Train Loss: 0.45 | Train Accuracy: 0.7825\n",
      "Epoch [13/50] Train Loss: 0.45 | Train Accuracy: 0.7830\n",
      "Epoch [14/50] Train Loss: 0.45 | Train Accuracy: 0.7812\n",
      "Epoch [15/50] Train Loss: 0.45 | Train Accuracy: 0.7824\n",
      "Epoch [16/50] Train Loss: 0.45 | Train Accuracy: 0.7826\n",
      "Epoch [17/50] Train Loss: 0.45 | Train Accuracy: 0.7817\n",
      "Epoch [18/50] Train Loss: 0.45 | Train Accuracy: 0.7825\n",
      "Epoch [19/50] Train Loss: 0.45 | Train Accuracy: 0.7822\n",
      "Epoch [20/50] Train Loss: 0.45 | Train Accuracy: 0.7824\n",
      "Epoch [21/50] Train Loss: 0.45 | Train Accuracy: 0.7826\n",
      "Epoch [22/50] Train Loss: 0.45 | Train Accuracy: 0.7828\n",
      "Epoch [23/50] Train Loss: 0.45 | Train Accuracy: 0.7828\n",
      "Epoch [24/50] Train Loss: 0.45 | Train Accuracy: 0.7833\n",
      "Epoch [25/50] Train Loss: 0.45 | Train Accuracy: 0.7840\n",
      "Epoch [26/50] Train Loss: 0.45 | Train Accuracy: 0.7835\n",
      "Epoch [27/50] Train Loss: 0.45 | Train Accuracy: 0.7836\n",
      "Epoch [28/50] Train Loss: 0.45 | Train Accuracy: 0.7842\n",
      "Epoch [29/50] Train Loss: 0.45 | Train Accuracy: 0.7847\n",
      "Epoch [30/50] Train Loss: 0.45 | Train Accuracy: 0.7834\n",
      "Epoch [31/50] Train Loss: 0.45 | Train Accuracy: 0.7839\n",
      "Epoch [32/50] Train Loss: 0.45 | Train Accuracy: 0.7829\n",
      "Epoch [33/50] Train Loss: 0.45 | Train Accuracy: 0.7837\n",
      "Epoch [34/50] Train Loss: 0.45 | Train Accuracy: 0.7844\n",
      "Epoch [35/50] Train Loss: 0.45 | Train Accuracy: 0.7830\n",
      "Epoch [36/50] Train Loss: 0.45 | Train Accuracy: 0.7844\n",
      "Epoch [37/50] Train Loss: 0.45 | Train Accuracy: 0.7849\n",
      "Epoch [38/50] Train Loss: 0.45 | Train Accuracy: 0.7846\n",
      "Epoch [39/50] Train Loss: 0.45 | Train Accuracy: 0.7838\n",
      "Epoch [40/50] Train Loss: 0.45 | Train Accuracy: 0.7844\n",
      "Epoch [41/50] Train Loss: 0.45 | Train Accuracy: 0.7847\n",
      "Epoch [42/50] Train Loss: 0.45 | Train Accuracy: 0.7849\n",
      "Epoch [43/50] Train Loss: 0.45 | Train Accuracy: 0.7853\n",
      "Epoch [44/50] Train Loss: 0.45 | Train Accuracy: 0.7857\n",
      "Epoch [45/50] Train Loss: 0.45 | Train Accuracy: 0.7851\n",
      "Epoch [46/50] Train Loss: 0.45 | Train Accuracy: 0.7844\n",
      "Epoch [47/50] Train Loss: 0.45 | Train Accuracy: 0.7845\n",
      "Epoch [48/50] Train Loss: 0.45 | Train Accuracy: 0.7846\n",
      "Epoch [49/50] Train Loss: 0.45 | Train Accuracy: 0.7856\n",
      "Epoch [50/50] Train Loss: 0.45 | Train Accuracy: 0.7855\n",
      "Training Completed ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    mlp_model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = mlp_model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        prob = torch.sigmoid(preds)\n",
    "        pred_label = (prob > 0.5).float()\n",
    "        correct += (pred_label == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = total_loss/len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} Train Loss: {loss:.2f} | Train Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"Training Completed ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, f1_score, roc_auc_score, roc_curve, auc)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def evaluate_model(model, loader, model_name):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probas = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            out = torch.sigmoid(model(xb))\n",
    "\n",
    "            prob = out.cpu().numpy()\n",
    "            preds = (prob > 0.5).astype(int)\n",
    "\n",
    "            all_probas.extend(prob)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(yb.numpy())\n",
    "\n",
    "    print(f\"\\n================= {model_name} =================\")\n",
    "    \n",
    "    ## Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=mlb.classes_))\n",
    "\n",
    "    ## Micro/Macro F1\n",
    "    print(\"Micro F1 Score:\", f1_score(all_labels, all_preds, average=\"micro\"))\n",
    "    print(\"Macro F1 Score:\", f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    ## ROC-AUC Scores\n",
    "    print(\"\\nROC-AUC per class:\")\n",
    "    for i, label in enumerate(mlb.classes_):\n",
    "        score = roc_auc_score([lbl[i] for lbl in all_labels],\n",
    "                              [prob[i] for prob in all_probas])\n",
    "        print(f\"{label}: {score:.3f}\")\n",
    "\n",
    "    macro_auc = roc_auc_score(all_labels, all_probas, average=\"macro\")\n",
    "    micro_auc = roc_auc_score(all_labels, all_probas, average=\"micro\")\n",
    "    print(f\"\\nMacro-Average ROC-AUC: {macro_auc:.3f}\")\n",
    "    print(f\"Micro-Average ROC-AUC: {micro_auc:.3f}\")\n",
    "\n",
    "    ## Plot ROC Curves\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i, label in enumerate(mlb.classes_):\n",
    "        fpr, tpr, _ = roc_curve([lbl[i] for lbl in all_labels],\n",
    "                                [prob[i] for prob in all_probas])\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{label} AUC={auc_score:.3f}\")\n",
    "    \n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.title(f\"ROC Curve â€” {model_name}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ## Confusion Matrix per Label\n",
    "    for i, label in enumerate(mlb.classes_):\n",
    "        cm = confusion_matrix([lbl[i] for lbl in all_labels],\n",
    "                              [pred[i] for pred in all_preds])\n",
    "\n",
    "        plt.figure(figsize=(3,3))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(f\"Confusion Matrix â€” {model_name}: {label}\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test_vec), torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "w2v_test_loader = DataLoader(w2v_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "evaluate_model(mlp_model, w2v_test_loader, \"GloVe Multi-Label DNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d05107",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "V_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
