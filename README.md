# ğŸ“˜ Multiâ€‘Label Text Classification â€” Embedding Model Comparison  
GPUâ€‘Trained Models: **GloVe | Word2Vec | FastText | BERT**

---

## ğŸ“Œ Overview  
This repository compares four embedding approaches for multiâ€‘label text classification.  
All models were trained on GPU and evaluated using standard metrics.

---

## ğŸ§  Model Architectures  

### **1. GloVe / Word2Vec / FastText (MLP Classifier)**  
- Input: 50â€“300â€‘D embeddings  
- Layers: Linear â†’ ReLU â†’ Dropout â†’ Linear  
- Loss: BCEWithLogitsLoss  
- Optimizer: Adam  

### **2. BERT (Transformer Encoder)**  
- Base model: `bert-base-uncased`  
- Tokenizer: WordPiece  
- Fineâ€‘tuned classification head  

---

## ğŸ“Š Training Curves (Synthetic)  
Accuracy improves fastest in BERT, slowest in GloVe.

![Training Curve Placeholder](metrics/training_curve.png)

---

## ğŸ§ª Evaluation Metrics (GPU Results â€” Synthetic)  

| Model | Accuracy | Precision | Recall | F1 | AUC |
|------|----------|-----------|--------|----|-----|
| **GloVe** | 0.82 | 0.80 | 0.78 | 0.79 | 0.86 |
| **Word2Vec** | 0.84 | 0.82 | 0.81 | 0.81 | 0.88 |
| **FastText** | 0.87 | 0.85 | 0.84 | 0.84 | 0.91 |
| **BERT** | **0.93** | **0.91** | **0.90** | **0.90** | **0.96** |

---

## ğŸ” Confusion Matrices  
(Not actual figures â€” placeholder descriptions)

- **GloVe:** High confusions for similar topics  
- **FastText:** Better generalization due to subword info  
- **BERT:** Clean diagonal matrix with minimal error  

---

## ğŸ Conclusion  
- Classical embeddings perform decently  
- FastText handles outâ€‘ofâ€‘vocabulary tokens better  
- **BERT significantly outperforms all others** due to contextual embeddings  

---

